"""
Autonomous Investment Research Agent

This agent demonstrates all required capabilities:
1. Plans its research steps for a given stock
2. Uses tools dynamically (APIs, datasets, retrieval)
3. Self-reflects to assess output quality
4. Learns across runs (memory/notes for improvement)

Integrates all three workflow patterns:
- Prompt Chaining: For news processing
- Routing: For content-specific analysis
- Evaluator-Optimizer: For self-improvement
"""
from typing import Dict, List, Optional
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from utils.llm_factory import create_chat_llm
from utils.knowledge_graph import KnowledgeGraphBuilder
from utils.data_fetchers import FinancialDataFetcher
from workflows.prompt_chaining import PromptChainWorkflow
from workflows.routing import RoutingWorkflow
from workflows.evaluator_optimizer import EvaluatorOptimizerWorkflow


class ResearchPlan(BaseModel):
    """Research plan generated by the agent."""
    ticker: str = Field(description="Stock ticker to research")
    research_steps: List[str] = Field(description="Ordered list of research steps")
    data_sources_needed: List[str] = Field(description="Data sources required")
    estimated_complexity: str = Field(description="low, medium, or high")
    key_questions: List[str] = Field(description="Key questions to answer")


class ResearchReflection(BaseModel):
    """Self-reflection on research quality."""
    completeness_score: float = Field(description="How complete is the research (0-100)")
    confidence_score: float = Field(description="Confidence in findings (0-100)")
    data_quality_score: float = Field(description="Quality of data sources (0-100)")

    strengths: List[str] = Field(description="Strong aspects of the research")
    gaps: List[str] = Field(description="Gaps or missing information")
    reliability_concerns: List[str] = Field(description="Data reliability issues")

    overall_assessment: str = Field(description="Overall quality assessment")
    improvement_recommendations: List[str] = Field(
        description="How to improve future research"
    )


class ResearchResult(BaseModel):
    """Final research output."""
    ticker: str
    plan: ResearchPlan
    knowledge_graph_summary: str
    news_analysis: Optional[Dict]
    specialized_analysis: Optional[Dict]
    investment_analysis: Optional[Dict]
    reflection: ResearchReflection
    execution_time_seconds: float


class AutonomousResearchAgent:
    """
    Autonomous agent that researches stocks and demonstrates:
    - Planning
    - Dynamic tool use
    - Self-reflection
    - Learning across runs
    """

    def __init__(
        self,
        llm: Optional[ChatOpenAI] = None,
        memory_file: str = "agent_memory.txt"
    ):
        """
        Initialize the autonomous research agent.

        Args:
            llm: Language model to use
            memory_file: File to store learnings across runs
        """
        self.llm = llm or create_chat_llm(temperature=0.3)
        self.memory_file = memory_file

        # Initialize components
        self.kg_builder = KnowledgeGraphBuilder()
        self.fetcher = FinancialDataFetcher()
        self.chaining_workflow = PromptChainWorkflow(llm)
        self.routing_workflow = RoutingWorkflow(llm)
        self.eo_workflow = EvaluatorOptimizerWorkflow(llm, max_iterations=2)

    def step1_plan_research(self, ticker: str, user_context: str = "") -> ResearchPlan:
        """
        AGENT FUNCTION 1: Plans research steps autonomously.

        Args:
            ticker: Stock ticker to research
            user_context: Optional context from user

        Returns:
            ResearchPlan with steps and requirements
        """
        print("\n=== STEP 1: PLANNING RESEARCH ===")

        # Load past learnings
        past_learnings = self._load_memory()

        structured_llm = self.llm.with_structured_output(ResearchPlan)

        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an autonomous investment research agent. Plan comprehensive research.

Your research plan should:
1. Break down the research into clear, ordered steps
2. Identify required data sources
3. List key questions that must be answered
4. Estimate research complexity

Consider past learnings to improve your approach:
{past_learnings}

Be thorough, systematic, and strategic."""),
            ("user", "Ticker: {ticker}\n\nUser Context: {user_context}\n\nCreate a research plan:")
        ])

        chain = prompt | structured_llm
        plan = chain.invoke({
            "ticker": ticker,
            "user_context": user_context or "General investment analysis",
            "past_learnings": past_learnings
        })

        print(f"✓ Research plan created with {len(plan.research_steps)} steps")
        print(f"  Complexity: {plan.estimated_complexity}")
        print(f"  Data sources: {', '.join(plan.data_sources_needed)}")

        return plan

    def step2_execute_research(self, plan: ResearchPlan) -> Dict:
        """
        AGENT FUNCTION 2: Uses tools dynamically based on plan.

        Dynamically selects and executes tools:
        - Knowledge graph expansion
        - News fetching and analysis
        - Routing to specialist analyzers
        - Investment analysis generation

        Args:
            plan: Research plan to execute

        Returns:
            Dictionary with research results
        """
        print("\n=== STEP 2: EXECUTING RESEARCH ===")
        results = {}

        # Tool 1: Build knowledge graph
        if "knowledge graph" in " ".join(plan.data_sources_needed).lower() or \
           "entity extraction" in " ".join(plan.data_sources_needed).lower():

            print("\n[Tool: Knowledge Graph] Building entity graph...")
            graph = self.kg_builder.expand_from_seed(
                plan.ticker,
                seed_label="STOCK_SYMBOL",
                depth=2
            )
            results["knowledge_graph"] = self.kg_builder.get_graph_summary()
            print(f"✓ Knowledge graph: {graph.number_of_nodes()} nodes")

        # Tool 2: Fetch and analyze news
        if "news" in " ".join(plan.data_sources_needed).lower():
            print("\n[Tool: News Analysis] Fetching recent news...")
            news_data = self.fetcher.fetch_yahoo_news(plan.ticker)

            if news_data and len(news_data) > 100:
                print("[Workflow: Prompt Chaining] Processing news...")
                news_summary = self.chaining_workflow.run(news_data, source="Yahoo Finance")
                results["news_analysis"] = {
                    "summary": news_summary.executive_summary,
                    "key_points": news_summary.key_points,
                    "category": news_summary.classification.category,
                    "sentiment": news_summary.classification.sentiment
                }
                print(f"✓ News analyzed: {news_summary.classification.category} / {news_summary.classification.sentiment}")

        # Tool 3: Route to specialized analyzer
        if "earnings" in " ".join(plan.data_sources_needed).lower() or \
           "market analysis" in " ".join(plan.data_sources_needed).lower():

            print("\n[Workflow: Routing] Routing to specialist...")
            # Fetch relevant content
            content = self.fetcher.fetch_alpha_vantage_quote(plan.ticker)

            if content and len(content) > 50:
                routing_result = self.routing_workflow.process(
                    content,
                    title=f"{plan.ticker} Financial Data"
                )
                results["specialized_analysis"] = {
                    "route": routing_result["routing_decision"].route,
                    "analysis_type": routing_result["analysis_type"]
                }
                print(f"✓ Routed to {routing_result['routing_decision'].route} analyst")

        # Tool 4: Generate comprehensive investment analysis
        print("\n[Workflow: Evaluator-Optimizer] Generating investment analysis...")

        # Compile available data
        compiled_data = self._compile_data_for_analysis(plan.ticker, results)

        eo_result = self.eo_workflow.run(
            plan.ticker,
            compiled_data,
            verbose=False
        )

        results["investment_analysis"] = {
            "recommendation": eo_result["final_analysis"].recommendation,
            "target_price": eo_result["final_analysis"].target_price,
            "thesis": eo_result["final_analysis"].investment_thesis,
            "quality_score": eo_result["final_evaluation"].overall_score,
            "iterations": eo_result["iterations_performed"]
        }

        print(f"✓ Investment analysis: {eo_result['final_analysis'].recommendation} "
              f"(quality: {eo_result['final_evaluation'].overall_score:.1f}/100)")

        return results

    def step3_reflect_on_quality(
        self,
        plan: ResearchPlan,
        results: Dict
    ) -> ResearchReflection:
        """
        AGENT FUNCTION 3: Self-reflects on research quality.

        Critically evaluates the completeness and quality of the research.

        Args:
            plan: Original research plan
            results: Research results

        Returns:
            ResearchReflection with quality assessment
        """
        print("\n=== STEP 3: SELF-REFLECTION ===")

        structured_llm = self.llm.with_structured_output(ResearchReflection)

        prompt = ChatPromptTemplate.from_messages([
            ("system", """You are reflecting on the quality of your own research. Be critical and honest.

Evaluate:
- Completeness: Did we answer all key questions?
- Confidence: How confident are we in the findings?
- Data Quality: Were the data sources reliable and sufficient?

Identify:
- Strengths: What did we do well?
- Gaps: What's missing or incomplete?
- Reliability concerns: Any data quality issues?

Provide honest self-assessment and concrete improvement recommendations."""),
            ("user", """Research Plan:
Ticker: {ticker}
Steps: {steps}
Key Questions: {questions}

Research Results:
{results}

Reflect on the quality of this research:""")
        ])

        chain = prompt | structured_llm
        reflection = chain.invoke({
            "ticker": plan.ticker,
            "steps": "\n".join(f"- {step}" for step in plan.research_steps),
            "questions": "\n".join(f"- {q}" for q in plan.key_questions),
            "results": str(results)[:3000]  # Limit length
        })

        print(f"✓ Self-reflection complete")
        print(f"  Completeness: {reflection.completeness_score:.1f}/100")
        print(f"  Confidence: {reflection.confidence_score:.1f}/100")
        print(f"  Data Quality: {reflection.data_quality_score:.1f}/100")
        print(f"  Gaps identified: {len(reflection.gaps)}")

        return reflection

    def step4_learn_from_run(self, reflection: ResearchReflection):
        """
        AGENT FUNCTION 4: Learns across runs.

        Stores insights and improvements for future research.

        Args:
            reflection: Reflection from this run
        """
        print("\n=== STEP 4: LEARNING ===")

        learning_entry = f"""
Run: {reflection.overall_assessment}
Improvements to apply:
{chr(10).join(f"- {rec}" for rec in reflection.improvement_recommendations)}
Gaps to avoid:
{chr(10).join(f"- {gap}" for gap in reflection.gaps)}
---
"""

        self._save_to_memory(learning_entry)
        print(f"✓ Learnings saved to {self.memory_file}")
        print(f"  {len(reflection.improvement_recommendations)} improvement recommendations stored")

    def research_stock(
        self,
        ticker: str,
        user_context: str = ""
    ) -> ResearchResult:
        """
        Execute complete autonomous research workflow.

        Demonstrates all required agent functions:
        1. Planning
        2. Dynamic tool use
        3. Self-reflection
        4. Learning

        Args:
            ticker: Stock ticker to research
            user_context: Optional context from user

        Returns:
            Complete research results with reflection
        """
        import time
        start_time = time.time()

        print("\n" + "="*80)
        print(f" AUTONOMOUS RESEARCH AGENT: {ticker}")
        print("="*80)

        # Step 1: Plan
        plan = self.step1_plan_research(ticker, user_context)

        # Step 2: Execute with dynamic tool selection
        results = self.step2_execute_research(plan)

        # Step 3: Self-reflect
        reflection = self.step3_reflect_on_quality(plan, results)

        # Step 4: Learn
        self.step4_learn_from_run(reflection)

        execution_time = time.time() - start_time

        print("\n" + "="*80)
        print(f" RESEARCH COMPLETE ({execution_time:.1f}s)")
        print("="*80 + "\n")

        return ResearchResult(
            ticker=ticker,
            plan=plan,
            knowledge_graph_summary=results.get("knowledge_graph", "Not generated"),
            news_analysis=results.get("news_analysis"),
            specialized_analysis=results.get("specialized_analysis"),
            investment_analysis=results.get("investment_analysis"),
            reflection=reflection,
            execution_time_seconds=execution_time
        )

    def _compile_data_for_analysis(self, ticker: str, results: Dict) -> str:
        """Compile research results into formatted text for analysis."""
        sections = [f"{ticker} Research Data\n"]

        if "knowledge_graph" in results:
            sections.append(f"Knowledge Graph:\n{results['knowledge_graph']}\n")

        if "news_analysis" in results:
            news = results["news_analysis"]
            sections.append(f"News Analysis:\n")
            sections.append(f"Summary: {news.get('summary', 'N/A')}\n")
            sections.append(f"Sentiment: {news.get('sentiment', 'N/A')}\n")

        # Add fetched financial data
        quote_data = self.fetcher.fetch_alpha_vantage_quote(ticker)
        if quote_data:
            sections.append(f"\n{quote_data}\n")

        return "\n".join(sections)

    def _load_memory(self) -> str:
        """Load past learnings from memory file."""
        try:
            with open(self.memory_file, 'r') as f:
                content = f.read()
                # Return last 2000 chars to fit in context
                return content[-2000:] if content else "No past learnings yet."
        except FileNotFoundError:
            return "No past learnings yet."

    def _save_to_memory(self, entry: str):
        """Append learning entry to memory file."""
        with open(self.memory_file, 'a') as f:
            f.write(entry)


def demonstrate_autonomous_agent():
    """Demonstration of the autonomous research agent."""

    agent = AutonomousResearchAgent()

    # Research a stock
    result = agent.research_stock(
        ticker="AAPL",
        user_context="Looking for long-term growth potential in tech sector"
    )

    # Display results
    print("\n" + "="*80)
    print(" RESEARCH RESULTS")
    print("="*80)

    print(f"\nTicker: {result.ticker}")
    print(f"Execution Time: {result.execution_time_seconds:.1f}s")

    print(f"\nResearch Plan:")
    for i, step in enumerate(result.plan.research_steps, 1):
        print(f"  {i}. {step}")

    if result.investment_analysis:
        print(f"\nInvestment Analysis:")
        print(f"  Recommendation: {result.investment_analysis['recommendation']}")
        print(f"  Target Price: ${result.investment_analysis['target_price']}")
        print(f"  Quality Score: {result.investment_analysis['quality_score']:.1f}/100")

    print(f"\nSelf-Reflection:")
    print(f"  Completeness: {result.reflection.completeness_score:.1f}/100")
    print(f"  Confidence: {result.reflection.confidence_score:.1f}/100")
    print(f"  Overall: {result.reflection.overall_assessment}")

    return result


if __name__ == "__main__":
    demonstrate_autonomous_agent()
